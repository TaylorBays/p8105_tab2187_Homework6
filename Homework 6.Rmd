---
title: "Homework 6"
output: github_document
date: "2022-11-29"
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
library(hexbin)
library(tidyr)
library(dplyr)
library(purrr)
library(rvest)
library(stringr)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


# Problem 1
To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 



# Problem 2

## Describe the raw data

In the raw data we see that we have 52,179 observations (criminal homicides) over the past decade in 51 of the largest American cities. The data set includes 12 variables including; the location of the killing, whether an arrest was made and, in most cases, basic demographic information about each victim. The data set is more specific than the federal homicide data gathered annually by the FBI from police agencies nationwide because reporters consulted public records, including death certificates, court records, and medical examiner reports, to fill in the gaps.

## Create a city_state variable (e.g. “Baltimore, MD”),and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. For this problem, limit your analysis those for whom victim_race is white or black. Be sure that victim_age is numeric. 

First, I combined the city and state variable so that they were one using `unite`.  Second, I filtered out the certain cities because they did not report `victim_race.` Third, I filtered out people who had an unknown age when arrested. Fifth, I changed the variable names within disposition so that we knew whether the cases were solved or unsolved. In Homework 5 we were told that the number of unsolved homicides were those for which the disposition is “Closed without arrest” or “Open/No arrest."

```{r}
homicide_data=
read.csv("homicide-data.csv") %>% 
janitor::clean_names() %>%
  unite("city_state", city:state) %>% 
filter(city_state != "Tulsa_AL") %>%
    filter(city_state != "Dallas_TX") %>%
    filter(city_state != "Phoenix_AZ") %>%
    filter(city_state != "Kansas City_MO") %>%  
filter(victim_race != "Hispanic") %>%
    filter(victim_race != "Other") %>% 
    filter(victim_race != "Asian") %>%
  filter(victim_race != "Unknown") %>% 
filter(victim_age != "Unknown") 

homicide_data$disposition = str_replace(homicide_data$disposition, "Closed without arrest", "Unsolved")
 homicide_data$disposition = str_replace(homicide_data$disposition, "Open/No arrest", "Unsolved") 
  homicide_data$disposition = str_replace(homicide_data$disposition, "Closed by arrest", "Solved")
```


## For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.


```{r}
baltimore_df = homicide_data %>% 
  filter(city_state == "Baltimore_MD") %>% 
  mutate(
    resolved = as.numeric(disposition == "Solved"),
    victim_age = as.numeric(victim_age),
    victim_sex = fct_relevel(victim_sex, "Male"),
    victim_race = fct_relevel(victim_race, "White")) %>% 
  select(resolved, victim_age, victim_race, victim_sex)
```

```{r}
fit_logistic = 
  baltimore_df %>% 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 

confint(fit_logistic)
```
Waiting for profiling to be done...
                       2.5 %        97.5 %
(Intercept)      -0.11709358  0.7161564202
victim_age       -0.01328188 -0.0002461094
victim_raceBlack -1.18660284 -0.5005491327
victim_sexFemale  0.58420169  1.1264230367



If we take the exponential for the `victim_sexFemale` we would see a confidence interval of (1.79356, 3.08460)
```{r}
fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) %>%
  select(term, log_OR = estimate, OR, p.value) %>% 
  knitr::kable(digits = 4)
```


## Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.


```
city_fitlogistic = homicide_data %>% 
  mutate(
    disposition= ifelse(disposition == "Unsolved", 0, 1)) %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(data, ~glm(disposition ~ victim_age + victim_race + victim_sex, data = ., family = binomial()))) 
```


```
results = map(city_fitlogistic$models, broom::tidy, conf.int = TRUE) %>% 
  select(city_state, models) %>% 
  unnest(cols = results)
```


## Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r}

```



# Problem 3

## Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

I have loaded the birthweight data and converted `gaweeks` to numeric.

```{r}
race_birthweight_df = read.csv("birthweight.csv") %>%
  mutate(
    gaweeks = as.numeric(gaweeks)) %>%
  select(mrace, bwt, gaweeks)

view(race_birthweight_df)
```


Premature = less than 37 weeks
Full Term = 37-42 weeks
Post Term = beyond 42 weeks gestation

I am using race and gestational age as predictors for birth weight because Black women have two times the rate of preterm birth compared to white women. In turn, since the babies are preterm they also weigh less. I wanted to see if this data would reveal what many research studies have revealed. 

## Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.

We are considering birth weight as an outcome that may depend on race and gestational age. 

```{r}
fit = lm(bwt ~ mrace + gaweeks, data = race_birthweight_df)
```

The `broom` package has functions for obtaining a summary of the model and for cleaning up the coefficient table. From here we can select what we actually want to look at. 

```{r}
fit %>% 
  broom::tidy ()
```
From the broom tidying we selected term, estimate, and p.value 

```{r}
fit %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(term = str_replace(term, "^gaweeks", "GaWeeks: ")) %>% 
  knitr::kable(digits = 3)
```


Here we want to look at residuals and predictions.
```{r}
modelr::add_residuals(race_birthweight_df, fit)
```


```{r}
modelr::add_predictions(race_birthweight_df, fit)
```


Next we combine the residual and prediction output with the modelr package so that we can visualize the outputs (a plot of model residuals against fitted values). Here we see a plot, that does not appear to have linearity.
```{r}
race_birthweight_df %>% 
  modelr::add_residuals(fit)%>%
  modelr::add_predictions(fit)%>%
  ggplot(aes(x = pred, y = resid)) + geom_point() + geom_hline(yintercept = 0)
```


## Compare your model to two others: One using length at birth and gestational age as predictors (main effects only). Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

Reading in the data
```{r}
birthweight_df = read.csv("birthweight.csv")
```

The plot below suggests non linearity especially at the higher end of the distribution. 

```{r}
birthweight_df %>% 
  ggplot(aes(x = blength, y = gaweeks)) +
  geom_point(alpha = 0.5)
```

For the piecewise linear fit, we need to add a “change point term” to our dataframe.

```{r}
birthweight_df =
  birthweight_df %>% 
  mutate(length_cp = (blength > 7) * (blength - 7))
```

The code chunk below fits each of the candidate models to the full dataset. The piecewise linear model is nested in the linear model and could be assessed using statistical significance, but the smooth model is not nested in anything else.
```{r}
linear_mod = lm(bwt ~ gaweeks + blength, data = birthweight_df)
pwl_mod    = lm(bwt ~ gaweeks + blength + length_cp, data = birthweight_df)
smooth_mod = gam(bwt ~ s(gaweeks) + s(blength), data = birthweight_df)
```

Plotting all three models to assess goodness of fit.
```{r}
birthweight_df %>% 
  gather_predictions(linear_mod, pwl_mod, smooth_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = blength, y = gaweeks)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```

The non-linear model looks much different than the linear model and the piecewise model.


Since I want to fit a gam model, I have to convert the resample objects produced by crossv_mc to dataframes, but wouldn’t have to do this if I only wanted to compare the linear and piecewise models.
```{r}
cv_df =
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

Next I’ll use mutate + map & map2 to fit models to training data and obtain corresponding RMSEs for the testing data.


```{r}
cv_df = 
  cv_df %>% 
  mutate(
    linear_mod  = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
    pwl_mod     = map(train, ~lm(bwt ~ gaweeks + blength + length_cp, data = .x)),
    smooth_mod  = map(train, ~gam(bwt ~ s(gaweeks) + s(blength), data = as_tibble(.x)))) %>% 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
    rmse_pwl    = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y)))
```


Finally, I’ll plot the prediction error distribution for each candidate model.
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```


There is some improvement in predictive accuracy gained by allowing non-linearity. If it is correct or enough to justify using this model, I am uncertain.

## One using head circumference, length, sex, and all interactions (including the three-way interaction) between these. Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

Reading in the data. Repeating the same steps as above.
```{r}
all_birthweight_df = read.csv("birthweight.csv")
```

The code chunk below fits each of the candidate models to the full dataset.
```{r}
linear_mod2 = lm(bwt ~ bhead + blength + babysex + (bhead * blength * babysex), data = all_birthweight_df)
```


Plotting all three models to assess goodness of fit.
```{r}
all_birthweight_df %>% 
  gather_predictions(linear_mod2) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```


```{r}
cv_df2 =
  crossv_mc(all_birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df2 = 
  cv_df2 %>% 
  mutate(
    linear_mod2  = map(train, ~lm(bwt ~ bhead + blength + babysex + (bhead * blength * babysex), data = .x))) %>% 
  mutate(
    rmse_linear = map2_dbl(linear_mod2, test, ~rmse(model = .x, data = .y))) 
```


The model produced below seems to encompass more than the models created above because it includes more predictors. The overall plot is wider and has more length.
```{r}
cv_df2 %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```